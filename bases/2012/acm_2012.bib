@article{10.5555/2503308.2503319,
author = {Aho, Timo and \v{Z}enko, Bernard and D\v{z}eroski, Sa\c{s}o and Elomaa, Tapio},
title = {Multi-Target Regression with Rule Ensembles},
year = {2012},
issue_date = {January 2012},
publisher = {JMLR.org},
volume = {13},
number = {1},
issn = {1532-4435},
abstract = {Methods for learning decision rules are being successfully applied to many problem domains, in particular when understanding and interpretation of the learned model is necessary. In many real life problems, we would like to predict multiple related (nominal or numeric) target attributes simultaneously. While several methods for learning rules that predict multiple targets at once exist, they are all based on the covering algorithm, which does not work well for regression problems. A better solution for regression is the rule ensemble approach that transcribes an ensemble of decision trees into a large collection of rules. An optimization procedure is then used to select the best (and much smaller) subset of these rules and to determine their respective weights.We introduce the FIRE algorithm for solving multi-target regression problems, which employs the rule ensembles approach. We improve the accuracy of the algorithm by adding simple linear functions to the ensemble. We also extensively evaluate the algorithm with and without linear functions. The results show that the accuracy of multi-target regression rule ensembles is high. They are more accurate than, for instance, multi-target regression trees, but not quite as accurate as multi-target random forests. The rule ensembles are significantly more concise than random forests, and it is also possible to create compact rule sets that are smaller than a single regression tree but still comparable in accuracy.},
journal = {J. Mach. Learn. Res.},
month = aug,
pages = {2367–2407},
numpages = {41},
keywords = {regression, multi-target prediction, rule ensembles, rule learning}
}

@inproceedings{10.1145/2229012.2229065,
author = {Jannach, Dietmar and Karakaya, Zeynep and Gedikli, Fatih},
title = {Accuracy Improvements for Multi-Criteria Recommender Systems},
year = {2012},
isbn = {9781450314152},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2229012.2229065},
doi = {10.1145/2229012.2229065},
abstract = {Recommender systems (RS) have shown to be valuable tools on e-commerce sites which help the customers identify the most relevant items within large product catalogs. In systems that rely on collaborative filtering, the generation of the product recommendations is based on ratings provided by the user community. While in many domains users are only allowed to attach an overall rating to the items, increasingly more online platforms allow their customers to evaluate the available items along different dimensions. Previous work has shown that these criteria ratings contain valuable information that can be exploited in the recommendation process.In this work we present new methods to leverage information derived from multi-dimensional ratings to improve the predictive accuracy of such multi-criteria recommender systems. In particular, we propose to use Support Vector regression to determine the relative importance of the individual criteria ratings and suggest to combine user- and item-based regression models in a weighted approach. Beside the automatic adjustment and optimization of the combination weights, we also explore different feature selection strategies to further improve the quality of the recommendations.An experimental analysis on two real-world rating datasets reveals that our method outperforms both recent single-rating algorithms based on matrix factorization as well as previous methods based on multi-criteria ratings in terms of the predictive accuracy.We therefore see the usage of multi-criteria customer ratings as a promising opportunity for e-commerce sites to improve the quality and precision of their online recommendation services.},
booktitle = {Proceedings of the 13th ACM Conference on Electronic Commerce},
pages = {674–689},
numpages = {16},
keywords = {machine learning, recommender systems, multi-criteria ratings},
location = {Valencia, Spain},
series = {EC '12}
}

@inproceedings{10.1145/2330163.2330318,
author = {Louren\c{c}o, Nuno and Horta, Nuno},
title = {GENOM-POF: Multi-Objective Evolutionary Synthesis of Analog ICs with Corners Validation},
year = {2012},
isbn = {9781450311779},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2330163.2330318},
doi = {10.1145/2330163.2330318},
abstract = {In this paper, a multi-objective design methodology and tool for automatic analog IC synthesis, which takes into account the effects of process variations, is presented. By varying the technological and environmental parameters, the robustness of the solutions is enhanced. The automatic analog IC sizing tool, GENOM-POF, was implemented to demonstrate the methodology and to verify the effects of corner cases on the Pareto optimal front (POF). The impacts of NSGA-II parameters when applied to analog circuit sizing were investigated, and three different design strategies were tested in a benchmark circuit, showing the effectiveness of multi-objective design of analog cells.},
booktitle = {Proceedings of the 14th Annual Conference on Genetic and Evolutionary Computation},
pages = {1119–1126},
numpages = {8},
keywords = {analog ic sizing, electronic design automation, computer aided design, multi-objective optimization, microelectronics},
location = {Philadelphia, Pennsylvania, USA},
series = {GECCO '12}
}

@inproceedings{10.5555/2429759.2429875,
author = {Abo-Hamad, Waleed and Arisha, Amr},
title = {Multi-Criteria Framework for Emergency Department in Irish Hospital},
year = {2012},
publisher = {Winter Simulation Conference},
abstract = {Health research is one of these priorities in every economy and through this research an emphasis will be put on translational research in the context of more sustainable and efficient healthcare system (translation of operations management practices to clinical applications). Healthcare systems in general and Emergency Departments in particular around the world are facing enormous challenges in meeting the increasingly conflicting objectives of providing wide accessibility and efficiency while delivering high quality and prompt services. The proposed framework integrates simulation modeling, balanced scorecard, and multi-criteria decision analysis aiming to provide a decision support system to emergency department managers. Simulation outputs are aggregated using analytic hierarchy process (AHP) to provide marginal performance regarding the achievement of the defined strategic as well as tactical and operational objectives. Communicating the significance of investigated strategies has encouraged managers to implement the framework recommendations in the emergency department within the hospital partner.},
booktitle = {Proceedings of the Winter Simulation Conference},
articleno = {88},
numpages = {12},
location = {Berlin, Germany},
series = {WSC '12}
}

@inproceedings{10.1145/2213836.2213850,
author = {Nanongkai, Danupon and Lall, Ashwin and Das Sarma, Atish and Makino, Kazuhisa},
title = {Interactive Regret Minimization},
year = {2012},
isbn = {9781450312479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2213836.2213850},
doi = {10.1145/2213836.2213850},
abstract = {We study the notion of regret ratio proposed in [19] Nanongkai et al. [VLDB10] to deal with multi-criteria decision making in database systems. The regret minimization query proposed in [19] Nanongkai et al. was shown to have features of both skyline and top-k: it does not need information from the user but still controls the output size. While this approach is suitable for obtaining a reasonably small regret ratio, it is still open whether one can make the regret ratio arbitrarily small. Moreover, it remains open whether reasonable questions can be asked to the users in order to improve efficiency of the process.In this paper, we study the problem of minimizing regret ratio when the system is enhanced with interaction. We assume that when presented with a set of tuples the user can tell which tuple is most preferred. Under this assumption, we develop the problem of interactive regret minimization where we fix the number of questions and tuples per question that we can display, and aim at minimizing the regret ratio. We try to answer two questions in this paper: (1) How much does interaction help? That is, how much can we improve the regret ratio when there are interactions? (2) How efficient can interaction be? In particular, we measure how many questions we have to ask the user in order to make her regret ratio small enough.We answer both questions from both theoretical and practical standpoints. For the first question, we show that interaction can reduce the regret ratio almost exponentially. To do this, we prove a lower bound for the previous approach (thereby resolving an open problem from [19] Nanongkai et al.), and develop an almost-optimal upper bound that makes the regret ratio exponentially smaller. Our experiments also confirm that, in practice, interactions help in improving the regret ratio by many orders of magnitude. For the second question, we prove that when our algorithm shows a reasonable number of points per question, it only needs a few questions to make the regret ratio small. Thus, interactive regret minimization seems to be a necessary and sufficient way to deal with multi-criteria decision making in database systems.},
booktitle = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},
pages = {109–120},
numpages = {12},
keywords = {skyline, top-k, regret minimization},
location = {Scottsdale, Arizona, USA},
series = {SIGMOD '12}
}

@inproceedings{10.1145/2187980.2188001,
author = {Kumar, Vikash},
title = {A Semantic Policy Sharing and Adaptation Infrastructure for Pervasive Communities},
year = {2012},
isbn = {9781450312301},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2187980.2188001},
doi = {10.1145/2187980.2188001},
abstract = {Rule based information processing has traditionally been vital in many aspects of business, process manufacturing and information science. The need for rules gets even more magnified when limitations of ontology development in OWL are taken into account. In conjunction, the potent combination of ontology and rule based applications could be the future of information processing and knowledge representation on the web. However, semantic rules tend to be very dependent on multitudes of parameters and context data making it less flexible for use in applications where users could benefit from each other by socially sharing intelligence in the form of policies. This work aims to address this issue arising in rule based semantic applications in the use cases of smart home communities and privacy aware m-commerce setting for mobile users. In this paper, we propose a semantic policy sharing and adaptation infrastructure that enables a semantic rule created in one set of environmental, physical and contextual settings to be adapted for use in a situation when those settings/parameters/context variables change. The focus will mainly be on behavioural policies in the smart home use case and privacy enforcing and data filtering policies in the m-commerce scenario. Finally, we look into the possibility of making this solution application independent so that the benefits of such a policy adaptation infrastructure could be exploited in other application settings as well.},
booktitle = {Proceedings of the 21st International Conference on World Wide Web},
pages = {155–160},
numpages = {6},
keywords = {rules, rule interchange, semantic web, smart home, m-commerce, policy transformation, policy sharing and adaptation, semantic policy},
location = {Lyon, France},
series = {WWW '12 Companion}
}

@inproceedings{10.1145/2361354.2361361,
author = {Moulder, Peter and Marriott, Kim},
title = {Learning How to Trade off Aesthetic Criteria in Layout},
year = {2012},
isbn = {9781450311168},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2361354.2361361},
doi = {10.1145/2361354.2361361},
abstract = {Typesetting software is often faced with conflicting aesthetic goals. For example, choosing where to break lines in text might involve aiming to minimize hyphenation, variation in word spacing, and consecutive lines starting with the same word. Typically, automatic layout is modelled as an optimization problem in which the goal is to minimize a complex objective function that combines various penalty functions each of which corresponds to a particular bad feature. Determining how to combine these penalty functions is difficult and very time consuming, becoming harder each time we add another penalty. Here we present a machine-learning approach to do this, and test it in the context of line-breaking. Our approach repeatedly queries the expert typographer as to which one of a pair of layouts is better, and accordingly refines the estimate of how best to weight the penalties in a linear combination. It chooses layout pair queries by a heuristic to maximize the amount that can be learnt from them so as to reduce the number of combinations that must be considered by the typographer.},
booktitle = {Proceedings of the 2012 ACM Symposium on Document Engineering},
pages = {33–36},
numpages = {4},
keywords = {typography, progressive articulation of preference, line-breaking, multi-objective optimization},
location = {Paris, France},
series = {DocEng '12}
}

@inproceedings{10.5555/2492708.2492964,
author = {Zuluaga, Marcela and Bonilla, Edwin and Topham, Nigel},
title = {Predicting Best Design Trade-Offs: A Case Study in Processor Customization},
year = {2012},
isbn = {9783981080186},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {Given the high level description of a task, many different hardware modules may be generated while meeting its behavioral requirements. The characteristics of the generated hardware can be tailored to favor energy efficiency, performance, accuracy or die area. The inherent trade-offs between such metrics need to be explored in order to choose a solution that meets design and cost expectations. We address the generic problem of automatically deriving a hardware implementation from a high-level task description. In this paper we present a novel technique that exploits previously explored implementation design spaces in order to find optimal trade-offs for new high-level descriptions. This technique is generalizable to a range of high-level synthesis problems in which trade-offs can be exposed by changing the parameters of the hardware generation tool. Our strategy, based upon machine learning techniques, models the impact of the parameterization of the tool on the target objectives, given the characteristics of the input. Thus, a predictor is able to suggest a subset of parameters that are likely to lead to optimal hardware implementations. The proposed method is evaluated on a resource sharing problem which is typical in high level synthesis, where the trade-offs between area and performance need to be explored. In this case study, we show that the technique can reduce by two orders of magnitude the number of design points that need to be explored in order to find the Pareto optimal solutions.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {1030–1035},
numpages = {6},
location = {Dresden, Germany},
series = {DATE '12}
}

@inproceedings{10.5555/2429759.2430020,
author = {Cheng, Junzilan and Fowler, John and Kempf, Karl},
title = {Simulation-Based Multi-Mode Resource-Constrained Project Scheduling of Semiconductor Equipment Installation and Qualification},
year = {2012},
publisher = {Winter Simulation Conference},
abstract = {Ramping up a semiconductor wafer fabrication facility is a challenging endeavor. One of the key components of this process is to contract and schedule multiple types of resources in installing and qualifying the capital intensive and sophisticated manufacturing equipment. Due to the stochastic nature of the business environment, equipment shipment delays and activity duration increases are common. We first model the process as a deterministic multi-mode resource-constrained project scheduling problem (MRCPSP) which is NP-hard in the strong sense. Then we extend the classical MRCPSP to handle special aspects of the semiconductor environment such as time-varying resource constraints and resource vacations, alternative resource modes, non-preemptive activity splitting, etc. In this research, a modified Simulated Annealing (SA) algorithm combined with Monte Carlo simulation is proposed to evaluate and improve the execution of the Install/qual schedule with stochastic ready times and activity durations. A case study is provided to demonstrate the approach.},
booktitle = {Proceedings of the Winter Simulation Conference},
articleno = {195},
numpages = {12},
location = {Berlin, Germany},
series = {WSC '12}
}

@inproceedings{10.1145/2462130.2462132,
author = {Zhang, Yong and Peng, Yi and Li, Jun and Kou, Gang and Shi, Yong},
title = {An Ensemble Clustering Model for Mining Concept Drifting Stream Data in Emergency Management},
year = {2012},
isbn = {9781450315517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2462130.2462132},
doi = {10.1145/2462130.2462132},
abstract = {Mining data streams with concept drifts is always an important and challenge task for researchers in both application and theory areas, such as emergency management. Because of requiring massive training data with labels, it is a hard and time costing work for existing (ensemble) classical models, sometimes even impossible. Aim to resolve this issue, in this paper; we propose an ensemble clustering model for mining concept drifting stream data in emergency management. Motivated by classifiers, the model will mine the data in two steps: "training" and "testing", just with a small training set. According to the experiment, the results demonstrate the effect and performance of the proposed model in mining data streams with concept drifts.},
booktitle = {Proceedings of the Data Mining and Intelligent Knowledge Management Workshop},
articleno = {2},
numpages = {8},
keywords = {concept drift, stream data, emergency management, clustering validity, ensemble clustering},
location = {Beijing, China},
series = {DM-IKM '12}
}

@inproceedings{10.5555/2666759.2666769,
author = {Salehie, Mazeiar and Pasquale, Liliana and Omoronyia, Inah and Nuseibeh, Bashar},
title = {Adaptive Security and Privacy in Smart Grids: A Software Engineering Vision},
year = {2012},
isbn = {9781467318648},
publisher = {IEEE Press},
abstract = {Despite the benefits offered by smart grids, energy producers, distributors and consumers are increasingly concerned about possible security and privacy threats. These threats typically manifest themselves at runtime as new usage scenarios arise and vulnerabilities are discovered. Adaptive security and privacy promise to address these threats by increasing awareness and automating prevention, detection and recovery from security and privacy requirements' failures at runtime by re-configuring system controls and perhaps even changing requirements. This paper discusses the need for adaptive security and privacy in smart grids by presenting some motivating scenarios. We then outline some research issues that arise in engineering adaptive security. We particularly scrutinize published reports by NIST on smart grid security and privacy as the basis for our discussions.},
booktitle = {Proceedings of the First International Workshop on Software Engineering Challenges for the Smart Grid},
pages = {46–49},
numpages = {4},
keywords = {adaptive software, security and privacy, security requirements, smart grid},
location = {Zurich, Switzerland},
series = {SE4SG '12}
}

@article{10.1145/2436239.2436244,
author = {Andoh-Baidoo, Francis Kofi and Osei-Bryson, Kweku-Muata and Amoako-Gyampah, Kwasi},
title = {A Hybrid Decision Tree Based Methodology for Event Studies and Its Application to E-Commerce Initiative Announcements},
year = {2012},
issue_date = {February 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {1},
issn = {0095-0033},
url = {https://doi.org/10.1145/2436239.2436244},
doi = {10.1145/2436239.2436244},
abstract = {The event study methodology has been applied in various business disciplines. This methodology typically has two goals: (1) to determine whether an event such as the announcement of an e-commerce initiative in the public media leads to cumulative abnormal returns (CAR); and (2) to examine the factors that influence the observed CAR. Most studies have used parametric statistical analysis in estimating CAR and regression for achieving the second goal. In this paper, we propose a hybrid methodology that involves using nonparametric statistical analysis to obtain the first goal, and the use of Decision Tree (DT) induction as a novel approach to reach the second goal. We apply the hybrid methodology to e-commerce announcements. The use of nonparametric analysis enables us to address some of the prior concerns of event study research in the e-commerce domain with regard to the limitations of short run event windows. The use of the novel DT-based approach leads to additional insights beyond what is reported in the literature through the examination of contingency effects. Specifically, our results indicate that the impact of Governance, Customer Type and Firm Type on CAR is contingent on the innovativeness of the e-commerce initiatives. Our study makes both methodological and theoretical contributions regarding the use of DT induction and nonparametric analysis in event studies especially in situations where prior studies present mixed results and where there are concerns about return variability. We present both research and managerial implications of the findings.},
journal = {SIGMIS Database},
month = nov,
pages = {78–101},
numpages = {24},
keywords = {e-commerce announcements, event study methodology, electronic commerce, decision tree induction, market value, nonparametric analysis}
}

@inproceedings{10.1007/978-3-642-31087-4_74,
author = {Huang, Chi-Yo and Wu, Ming-Jenn and Liu, Yu-Wei and Tzeng, Gwo-Hshiung},
title = {Using the DEMATEL Based Network Process and Structural Equation Modeling Methods for Deriving Factors Influencing the Acceptance of Smart Phone Operation Systems},
year = {2012},
isbn = {9783642310867},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/978-3-642-31087-4_74},
doi = {10.1007/978-3-642-31087-4_74},
abstract = {Smartphones have emerged as one of the most important consumer-electronic products during the past years. Therefore, researches on factors influencing consumers' behavior and thus, repurchase intention toward smartphones become the most critical issue for smartphone marketers. The smartphone operation system (OS) is one of the major factors influencing consumers' purchase decisions toward purchasing smartphones. However, the analysis and predictions of consumer behaviors toward the smartphone OSs are not easy due to due to the fast emerging technology and highly competitive market situation. To resolve this problem, this research aims to propose a novel multiple criteria decision making (MCDM) based approach for discovering the factors influencing the technology acceptances of the smartphone OSs based on industry experts' opinions. The opinions of mass users will also be summarized by using the Structural Equation Modeling (SEM) based Technology Acceptance Model (TAM) for comparisons. Differences of the analytic results being derived by the two analytic frameworks will be compared. Both the analytic framework and results can serve as the basis for future smartphone marketers' uses for strategy definitions.},
booktitle = {Proceedings of the 25th International Conference on Industrial Engineering and Other Applications of Applied Intelligent Systems: Advanced Research in Applied Artificial Intelligence},
pages = {731–741},
numpages = {11},
keywords = {decision making trial and evaluation laboratory (DEMATEL), technology acceptance model (TAM), structural equation modeling (SEM), lead user theory},
location = {Dalian, China},
series = {IEA/AIE'12}
}

