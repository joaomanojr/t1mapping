@inproceedings{10.1145/2676662.2676676,
author = {Samreen, Faiza and Blair, Gordon S. and Rowe, Matthew},
title = {Adaptive Decision Making in Multi-Cloud Management},
year = {2014},
isbn = {9781450332330},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2676662.2676676},
doi = {10.1145/2676662.2676676},
abstract = {The more cloud providers in the market the more information users have to handle to choose the best and suitable option for their application or business. The diversity in cloud services is a challenge for automated decision making in the multi-cloud environment. These decisions become more complex when the application's requirements and the application owner's constraints need to be satisfied throughout the application life cycle.This paper presents the concept of an Adaptive Decision Making Broker (ADMB) for multi-cloud management. ADMB aims to provide multi-criteria decision making using machine learning in a multi-cloud environment. In this context, we believe that our proposed methodology has the potential to provide optimal solutions as well as handle trade-offs between the functional and the non-functional requirements of given application.},
booktitle = {Proceedings of the 2nd International Workshop on CrossCloud Systems},
articleno = {4},
numpages = {6},
keywords = {multi-criteria decision making, machine learning, multi-cloud management},
location = {Bordeaux, France},
series = {CCB '14}
}

@inproceedings{10.1145/2668260.2668277,
author = {Elomda, Basem Mohamed and Hefny, Hesham Ahmed and Hazman, Maryam and Hassan, Hesham Ahmed},
title = {An Enhanced Method for MCDM Based on Improved Fuzzy Decision Map},
year = {2014},
isbn = {9781450327671},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2668260.2668277},
doi = {10.1145/2668260.2668277},
abstract = {Fuzzy Decision Map (FDM) method was proposed in 2006 to solve multicriteria decision making problems (MCDM) having dependence and feedback among criteria. FDM provides a simpler approach to solve such problems compared with the method of Analytical Network Process (ANP) developed in 1996. ANP is a general form of the Analytic Hierarchy Process (AHP). On the other hand, FDM is only employed to derive evaluation criteria. It can't be used for ranking alternatives as usually required in many real world MCDM problems. The aim of this work is to enhance the FDM structure to be able to make a proper decision for complex decision making problem by selecting best alternative. The enhanced FDM method should take into consideration the alternative level. A case study was carried out to demonstrate the proposed model.},
booktitle = {Proceedings of the 6th International Conference on Management of Emergent Digital EcoSystems},
pages = {56–61},
numpages = {6},
keywords = {Fuzzy Decision Map, Multi Criteria Decision Making, Fuzzy Cognitive Map, Fuzzy Set theory, Soft Computing},
location = {Buraidah, Al Qassim, Saudi Arabia},
series = {MEDES '14}
}

@inproceedings{10.1145/2670291.2670292,
author = {Hueting, Moos and Monszpart, Aron and Mellado, Nicolas},
title = {MCGraph: Multi-Criterion Representation for Scene Understanding},
year = {2014},
isbn = {9781450332422},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2670291.2670292},
doi = {10.1145/2670291.2670292},
abstract = {The field of scene understanding endeavours to extract a broad range of information from 3D scenes. Current approaches exploit one or at most a few different criteria (e.g., spatial, semantic, functional information) simultaneously for analysis. We argue that to take scene understanding to the next level of performance, we need to take into account many different, and possibly previously unconsidered types of knowledge simultaneously. A unified representation for this type of processing is as of yet missing. In this work we propose MCGraph: a unified multi-criterion data representation for understanding and processing of large-scale 3D scenes. Scene abstraction and prior knowledge are kept separated, but highly connected. For this purpose, primitives (i.e., proxies) and their relationships (e.g., contact, support, hierarchical) are stored in an abstraction graph, while the different categories of prior knowledge necessary for processing are stored separately in a knowledge graph. These graphs complement each other bidirectionally, and are processed concurrently. We illustrate our approach by expressing previous techniques using our formulation, and present promising avenues of research opened up by using such a representation. We also distribute a set of MCGraph annotations for a small number of NYU2 scenes, to be used as ground truth multi-criterion abstractions.},
booktitle = {SIGGRAPH Asia 2014 Indoor Scene Understanding Where Graphics Meets Vision},
articleno = {3},
numpages = {9},
keywords = {multi-criteria, scene understanding, scene abstraction},
location = {Shenzhen, China},
series = {SA '14}
}

@inproceedings{10.1145/2598394.2605339,
author = {Brockhoff, Dimo},
title = {GECCO 2014 Tutorial on Evolutionary Multiobjective Optimization},
year = {2014},
isbn = {9781450328814},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2598394.2605339},
doi = {10.1145/2598394.2605339},
abstract = {Many optimization problems are multiobjective in nature in the sense that multiple, conflicting criteria need to be optimized simultaneously. Due to the conflict between objectives, usually, no single optimal solution exists. Instead, the optimum corresponds to a set of so-called Pareto-optimal solutions for which no other solution has better function values in all objectives.Evolutionary Multiobjective Optimization (EMO) algorithms are widely used in practice for solving multiobjective optimization problems due to several reasons. As stochastic blackbox algorithms, EMO approaches allow to tackle problems with nonlinear, nondifferentiable, or noisy objective functions. As set-based algorithms, they allow to compute or approximate the full set of Pareto-optimal solutions in one algorithm run---opposed to classical solution-based techniques from the multicriteria decision making (MCDM) field. Using EMO approaches in practice has two other advantages: they allow to learn about a problem formulation, for example, by automatically revealing common design principles among (Pareto-optimal) solutions (innovization) and it has been shown that certain single-objective problems become easier to solve with randomized search heuristics if the problem is reformulated as a multiobjective one (multiobjectivization).This tutorial aims at giving a broad introduction to the EMO field and at presenting some of its recent research results in more detail. More specifically, we are going to (i) introduce the basic principles of EMO algorithms in comparison to classical solution-based approaches, (ii) show a few practical examples which motivate the use of EMO in terms of the mentioned innovization and multiobjectivization principles, and (iii) present a general overview of state-of-the-art algorithms and techniques. Moreover, we will present some of the most important research results in areas such as indicator-based EMO, preference articulation, and performance assessment.Though classified as introductory, this tutorial is intended for both novices and regular users of EMO. Those without any knowledge will learn about the foundations of multiobjective optimization and the basic working principles of state-of-the-art EMO algorithms. Open questions, presented throughout the tutorial, can serve for all participants as a starting point for future research and/or discussions during the conference.},
booktitle = {Proceedings of the Companion Publication of the 2014 Annual Conference on Genetic and Evolutionary Computation},
pages = {297–322},
numpages = {26},
keywords = {tutorial, emo, multi-criteria decision making, evolutionary multiobjective optimization},
location = {Vancouver, BC, Canada},
series = {GECCO Comp '14}
}

@inproceedings{10.5555/2693848.2694161,
author = {Tan, Yi and M\"{o}nch, Lars and Fowler, John W.},
title = {A Decomposition Heuristic for a Two-Machine Flow Shop with Batch Processing},
year = {2014},
publisher = {IEEE Press},
abstract = {In this paper, we discuss a two-stage flow shop scheduling problem with batch processing machines. The jobs belong to different incompatible job families. Only jobs of the same job family can be batched together. The performance measure is the total weighted tardiness of the jobs. A decomposition heuristic is proposed that is based on the idea to iteratively determine due dates for the jobs in the first stage and earliest start dates of the jobs in the second stage. The two resulting subproblems are solved using a time window decomposition (TWD) heuristic and a variable neighborhood search (VNS) scheme. Results of computational experiments based on randomly generated problem instances are presented. We show that the VNS-based scheme outperforms the TWD heuristic. In addition, we show that the decomposition scheme can be parallelized in a very natural way. As a result, the amount of computing time is modest, even for the computational expensive VNS scheme.},
booktitle = {Proceedings of the 2014 Winter Simulation Conference},
pages = {2490–2501},
numpages = {12},
location = {Savannah, Georgia},
series = {WSC '14}
}

@article{10.1162/EVCO_a_00128,
author = {Giagkiozis, Ioannis and Fleming, Peter J.},
title = {Pareto Front Estimation for Decision Making},
year = {2014},
issue_date = {Winter 2014},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {22},
number = {4},
issn = {1063-6560},
url = {https://doi.org/10.1162/EVCO_a_00128},
doi = {10.1162/EVCO_a_00128},
abstract = {The set of available multi-objective optimisation algorithms continues to grow. This fact can be partially attributed to their widespread use and applicability. However, this increase also suggests several issues remain to be addressed satisfactorily. One such issue is the diversity and the number of solutions available to the decision maker (DM). Even for algorithms very well suited for a particular problem, it is difficult—mainly due to the computational cost—to use a population large enough to ensure the likelihood of obtaining a solution close to the DM's preferences. In this paper we present a novel methodology that produces additional Pareto optimal solutions from a Pareto optimal set obtained at the end run of any multi-objective optimisation algorithm for two-objective and three-objective problem instances.},
journal = {Evol. Comput.},
month = dec,
pages = {651–678},
numpages = {28},
keywords = {Pareto front estimation, multi-objective optimization, evolutionary algorithms, nonlinear estimation, RBFNN}
}

@article{10.1145/2601439,
author = {Zhang, Gensheng and Jiang, Xiao and Luo, Ping and Wang, Min and Li, Chengkai},
title = {Discovering General Prominent Streaks in Sequence Data},
year = {2014},
issue_date = {June 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {1556-4681},
url = {https://doi.org/10.1145/2601439},
doi = {10.1145/2601439},
abstract = {This article studies the problem of prominent streak discovery in sequence data. Given a sequence of values, a prominent streak is a long consecutive subsequence consisting of only large (small) values, such as consecutive games of outstanding performance in sports, consecutive hours of heavy network traffic, and consecutive days of frequent mentioning of a person in social media. Prominent streak discovery provides insightful data patterns for data analysis in many real-world applications and is an enabling technique for computational journalism. Given its real-world usefulness and complexity, the research on prominent streaks in sequence data opens a spectrum of challenging problems.A baseline approach to finding prominent streaks is a quadratic algorithm that exhaustively enumerates all possible streaks and performs pairwise streak dominance comparison. For more efficient methods, we make the observation that prominent streaks are in fact skyline points in two dimensions—streak interval length and minimum value in the interval. Our solution thus hinges on the idea to separate the two steps in prominent streak discovery: candidate streak generation and skyline operation over candidate streaks. For candidate generation, we propose the concept of local prominent streak (LPS). We prove that prominent streaks are a subset of LPSs and the number of LPSs is less than the length of a data sequence, in comparison with the quadratic number of candidates produced by the brute-force baseline method. We develop efficient algorithms based on the concept of LPS. The nonlinear local prominent streak (NLPS)-based method considers a superset of LPSs as candidates, and the linear local prominent streak (LLPS)-based method further guarantees to consider only LPSs. The proposed properties and algorithms are also extended for discovering general top-k, multisequence, and multidimensional prominent streaks. The results of experiments using multiple real datasets verified the effectiveness of the proposed methods and showed orders of magnitude performance improvement against the baseline method.},
journal = {ACM Trans. Knowl. Discov. Data},
month = jun,
articleno = {9},
numpages = {37},
keywords = {Computational journalism, time series database, sequence database, skyline query}
}

